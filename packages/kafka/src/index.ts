/* ====================================================================
 * OmniQueue – Kafka adapter (node-rdkafka, Core vNext)
 * ==================================================================== */
import {
   Broker,
   BrokerMessage,
   ConsumeOptions,
   register,
   SendOptions,
} from '@omniqueue/core';
import Kafka, {
   IAdminClient,
   KafkaConsumer,
   Message,
   MessageHeader,
   Producer,
} from 'node-rdkafka';
import { ulid } from 'ulid';
import { DEFAULT_NUM_TOPIC, DEFAULT_REPLICATION_FACTOR } from './constant';

/* ─────────────── user-supplied connection & defaults ─────────────── */
export interface KafkaConfig {
   /** Bootstrap servers list, e.g. "localhost:9092" */
   brokers: string | string[];
   /** Optional logical client-id (else autogenerated) */
   clientId?: string;
   /** Extra low-level producer / consumer tuning */
   producerConfig?: Kafka.ProducerGlobalConfig;
   consumerConfig?: Kafka.ConsumerGlobalConfig;

   /** Default topic settings used when `ensure` = true */
   defaultTopic?: {
      numPartitions?: number; // default 1
      replicationFactor?: number; // default 1
      configEntries?: Record<string, string>;
   };
}

export type KafkaSendOptions = SendOptions & {
   headers?: MessageHeader[];
};

/* Map logical priority (0-N) → partition index (0-N) */
const prioToPartition = (prio = 0) => prio;

/* =================================================================== */
export class KafkaBroker implements Broker<KafkaSendOptions, ConsumeOptions> {
   readonly provider = 'kafka' as const;
   readonly config: any;

   private producer!: Producer;
   private admin!: IAdminClient;

   constructor(private cfg: KafkaConfig) {
      this.config = cfg;
   }

   /* ------------------ bootstrap connections ------------------------ */
   async init() {
      const bootstrap = Array.isArray(this.cfg.brokers)
         ? this.cfg.brokers.join(',')
         : this.cfg.brokers;

      const common: Kafka.GlobalConfig = {
         'bootstrap.servers': bootstrap,
         'client.id': this.cfg.clientId ?? `omniqueue-${ulid()}`,
      };

      this.admin = Kafka.AdminClient.create(common);

      this.producer = new Kafka.Producer({
         ...common,
         dr_cb: true, // delivery-report callback
         ...this.cfg.producerConfig,
      });

      await new Promise<void>((res, rej) => {
         this.producer.connect({}, (err) => (err ? rej(err) : res()));
      });
   }

   /* ---------------- topic-creation helper -------------------------- */
   /**
    * Ensure a topic exists with the given name and options.
    * If the topic already exists, this is a no-op.
    * If the topic does not exist, it will be created with the specified
    * number of partitions and replication factor.
    * If the topic creation fails with an error other than "topic already exists",
    * the promise will be rejected with that error.
    * 
    * For this to work, the Kafka user must have the necessary permissions
    * to create topics.
    * 
    * Typically: `topic.creation.enable` and `auto.create.topics.enable` configuration should be set to true
    * in the Kafka broker configuration.
    * 
    * @see: [auto.create.topics.enable](https://kafka.apache.org/documentation/#brokerconfigs_auto.create.topics.enable)
    * @see: [topic.creation.enable](https://kafka.apache.org/documentation/#connectconfigs_topic.creation.enable)
    */
   private async ensureTopic(
      topic: string,
      opts: Record<string, any> | undefined,
   ) {
      return new Promise<void>((res, rej) => {
         this.admin.createTopic(
            {
               topic,
               num_partitions:
                  opts?.numPartitions ??
                  this.cfg.defaultTopic?.numPartitions ??
                  DEFAULT_NUM_TOPIC,
               replication_factor:
                  opts?.replicationFactor ??
                  this.cfg.defaultTopic?.replicationFactor ??
                  DEFAULT_REPLICATION_FACTOR,
               config:
                  opts?.configEntries ?? this.cfg.defaultTopic?.configEntries,
            },
            (err) => {
               if (
                  err &&
                  err.code !== Kafka.CODES.ERRORS.ERR_TOPIC_ALREADY_EXISTS
               )
                  return rej(err);
               res();
            },
         );
      });
   }

   /* --------------- fan-out (same publish semantics) --------------- */
   async publish(
      topic: string,
      msg: Omit<BrokerMessage, 'ack' | 'nack'>,
      opts: KafkaSendOptions = {},
   ): Promise<void> {
      if (opts.ensure) await this.ensureTopic(topic, opts.createOptions);

      await new Promise<void>(async (res, rej) => {
         try {
            this.producer.produce(
               topic,
               prioToPartition(opts.prio),
               Buffer.from(JSON.stringify(msg.body)),
               msg.id, // key → stick to same partition on retries
               Date.now(),
               undefined,
               opts.headers ?? [],
            );
            res();
         } catch (err) {
            rej(err);
            return;
         }
      });
   }

   async subscribe(
      topic: string,
      handler: (m: BrokerMessage) => Promise<void>,
      groupId: string,
      opts: ConsumeOptions,
   ): Promise<void> {
      if (opts.ensure) await this.ensureTopic(topic, opts.createOptions);

      const consumer: KafkaConsumer = new Kafka.KafkaConsumer(
         {
            'bootstrap.servers': Array.isArray(this.cfg.brokers)
               ? this.cfg.brokers.join(',')
               : this.cfg.brokers,
            'group.id': groupId,
            'enable.auto.commit': false,
            ...this.cfg.consumerConfig,
         },
         {},
      );

      consumer.connect();
      consumer.on('ready', () => {
         consumer.subscribe([topic]);
         consumer.consume();
      });

      consumer.on('data', async (raw: Message) => {
         const brokerMsg: BrokerMessage = {
            id: raw.key?.toString() ?? ulid(),
            body: JSON.parse(raw.value!.toString()),
            headers: (raw.headers as any) ?? {},
            ack: async () => {
               await consumer.commit(raw);
               /*consume new messages after acking */
            },
            nack: async () => {
               /* do nothing → redeliver */
               /* Consume new messages after nack */
            },
         };
         try {
            await handler(brokerMsg);
            await brokerMsg.ack();
         } catch {
            await brokerMsg.nack();
         }
      });
   }

   /* ------------- lifecycle / teardown ---------------------------- */
   async close(): Promise<void> {
      await new Promise((r) => this.producer.disconnect(r));
      await new Promise((r) => {
         this.admin.disconnect();
         r(0);
      });
   }
}

/* Register with OmniQueue core */
register('kafka', async (cfg: KafkaConfig) => {
   const broker = new KafkaBroker(cfg);
   // private init before first use
   await (broker as any).init();
   return broker;
});
